{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e71c078",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27644e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from unidecode import unidecode\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed07ec",
   "metadata": {},
   "source": [
    "Etape 5: Entraînez un modèle word2vec (word embeddings) + adapter (éventuellement) les paramètres window (taille de la fenêtre) et min_count (nombre minimum d’occurrences d’un mot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f38d5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un objet qui *streame* les lignes d'un fichier pour économiser de la RAM\n",
    "class MySentences(object):\n",
    "    \"\"\"Tokenize and Lemmatize sentences\"\"\"\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in open(self.filename, encoding='utf-8', errors=\"backslashreplace\"):\n",
    "            yield [unidecode(w.lower()) for w in wordpunct_tokenize(line)]\n",
    "            \n",
    "infile = f\"../../data/sents.txt\"\n",
    "sentences = MySentences(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b29bd3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un corpus d'unigrams, bigrams, trigrams\n",
    "bigram_phrases = Phrases(sentences)\n",
    "bigram_phraser = Phraser(phrases_model=bigram_phrases)\n",
    "trigram_phrases = Phrases(bigram_phraser[sentences])\n",
    "trigram_phraser = Phraser(phrases_model=trigram_phrases)\n",
    "corpus = list(trigram_phraser[bigram_phraser[sentences]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb0567bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time : 1615.125 s\n",
      "Walltime: 794.9386912999908 s\n"
     ]
    }
   ],
   "source": [
    "# Entrainement du modèle word2vec\n",
    "# %%time #==> ne marche pas\n",
    "\n",
    "start1 = time.perf_counter()\n",
    "start2 = time.process_time()\n",
    "model1 = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=32, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=5, # La taille du \"contexte\", ici 5 mots avant et après le mot observé (5 mots avant + 5 mots après)\n",
    "    min_count=5, # On ignore les mots qui n'apparaissent pas au moins 5 fois dans le corpus\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descente de gradient, aka. epochs.\n",
    ")\n",
    "#\n",
    "end2 = time.process_time()\n",
    "end1 = time.perf_counter()\n",
    "\n",
    "\n",
    "print(\"CPU time :\", end2 - start2, \"s\")\n",
    "print(\"Walltime:\", end1 - start1, \"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fed1e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time : 1692.84375 s\n",
      "Walltime: 888.8154031000158 s\n"
     ]
    }
   ],
   "source": [
    "start1 = time.perf_counter()\n",
    "start2 = time.process_time()\n",
    "model2 = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=32, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=8, # La taille du \"contexte\", ici 5 mots avant et après le mot observé (5 mots avant + 5 mots après)\n",
    "    min_count=5, # On ignore les mots qui n'apparaissent pas au moins 5 fois dans le corpus\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descente de gradient, aka. epochs.\n",
    ")\n",
    "#\n",
    "end2 = time.process_time()\n",
    "end1 = time.perf_counter()\n",
    "\n",
    "print(\"CPU time :\", end2 - start2, \"s\")\n",
    "print(\"Walltime:\", end1 - start1, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4de4ba89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time : 2424.890625 s\n",
      "Walltime: 1126.4086258999887 s\n"
     ]
    }
   ],
   "source": [
    "start1 = time.perf_counter()\n",
    "start2 = time.process_time()\n",
    "model3 = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=32, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=5, # La taille du \"contexte\", ici 5 mots avant et après le mot observé (5 mots avant + 5 mots après)\n",
    "    min_count=2, # On ignore les mots qui n'apparaissent pas au moins 5 fois dans le corpus\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descente de gradient, aka. epochs.\n",
    ")\n",
    "#\n",
    "end2 = time.process_time()\n",
    "end1 = time.perf_counter()\n",
    "\n",
    "print(\"CPU time :\", end2 - start2, \"s\")\n",
    "print(\"Walltime:\", end1 - start1, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38e1504b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time : 2574.453125 s\n",
      "Walltime: 1091.7135911000078 s\n"
     ]
    }
   ],
   "source": [
    "start1 = time.perf_counter()\n",
    "start2 = time.process_time()\n",
    "model4 = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=32, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=8, # La taille du \"contexte\", ici 5 mots avant et après le mot observé (5 mots avant + 5 mots après)\n",
    "    min_count=2, # On ignore les mots qui n'apparaissent pas au moins 5 fois dans le corpus\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descente de gradient, aka. epochs.\n",
    ")\n",
    "#\n",
    "end2 = time.process_time()\n",
    "end1 = time.perf_counter()\n",
    "\n",
    "print(\"CPU time :\", end2 - start2, \"s\")\n",
    "print(\"Walltime:\", end1 - start1, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a63d6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1, model2, model3, model4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1b126",
   "metadata": {},
   "source": [
    "Etape 7: Explorez le modèle retenu à l’aide des fonctions similarity et most_similar (trois exemples pour chaque fonction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5e364ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couple de mot fortement lié\n",
      "modèle 1: 0.53389823\n",
      "modèle 2: 0.51810145\n",
      "modèle 3: 0.55058235\n",
      "modèle 4: 0.55070615\n",
      "Couple de mot moyennement lié\n",
      "modèle 1: 0.36210838\n",
      "modèle 2: 0.32590276\n",
      "modèle 3: 0.37309307\n",
      "modèle 4: 0.32606763\n",
      "Couple de mot négativement lié\n",
      "modèle 1: 0.018428534\n",
      "modèle 2: -0.08880977\n",
      "modèle 3: 0.1115908\n",
      "modèle 4: -0.093228504\n"
     ]
    }
   ],
   "source": [
    "# Explorer le modèle avec similarity\n",
    "print(\"Couple de mot fortement lié\")\n",
    "for i in range(len(models)):\n",
    "    print(\"modèle \" + str(i+1)+ \": \" + str(models[i].wv.similarity(\"roi\", \"reine\")))\n",
    "    \n",
    "print(\"Couple de mot moyennement lié\")\n",
    "for i in range(len(models)):\n",
    "    print(\"modèle \" + str(i+1) + \": \" + str(models[i].wv.similarity(\"travail\", \"ouvrier\")))\n",
    "\n",
    "print(\"Couple de mot négativement lié\")\n",
    "for i in range(len(models)):\n",
    "    print(\"modèle \" + str(i+1) + \": \" + str(models[i].wv.similarity(\"guerre\", \"cuisine\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7634701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple 1(guerre):\n",
      "modèle 1: \n",
      "[('liberation', 0.9137529134750366), ('guerro', 0.8887047171592712), ('derniere_guerre', 0.8718257546424866), ('wehrmacht', 0.8489624261856079), ('population', 0.8462672829627991), ('guorre', 0.8428082466125488), ('population_civile', 0.822415292263031), ('guorro', 0.818413496017456), ('guerre_mondiale', 0.8178240060806274), ('separation', 0.8152499794960022), ('colonie', 0.8130805492401123), ('reconnaissance', 0.8119193315505981), ('revolution', 0.8026339411735535), ('communaute', 0.8017407655715942), ('premiere_guerre_mondiale', 0.7986695170402527), ('capitulation', 0.7974178791046143), ('republique_federale', 0.7964221239089966), ('vie_politique', 0.7939084768295288), ('guerre_civile', 0.7934905886650085), ('marine_britannique', 0.7930331230163574)]\n",
      "modèle 2: \n",
      "[('liberation', 0.8935251235961914), ('guerro', 0.8583217263221741), ('derniere_guerre', 0.852436900138855), ('guerre_mondiale', 0.8255516290664673), ('capitulation', 0.81919926404953), ('wehrmacht', 0.8074957728385925), ('guorro', 0.8059830069541931), ('premiere_guerre_mondiale', 0.8033826947212219), ('guorre', 0.8018717169761658), ('mobilisation', 0.7972229719161987), ('reichswehr', 0.7930933237075806), ('seconde_guerre_mondiale', 0.7900781631469727), ('vie_civile', 0.7878614664077759), ('guerre_civile', 0.7853695154190063), ('russie_sovietique', 0.7850989699363708), ('palestine', 0.7837045788764954), ('reconnaissance', 0.7813034057617188), ('demobilisation', 0.7765040993690491), ('libye', 0.766089916229248), ('separation', 0.7660794258117676)]\n",
      "modèle 3: \n",
      "[('liberation', 0.9004793167114258), ('derniere_guerre', 0.8893133401870728), ('guerro', 0.8511394262313843), ('population', 0.836493730545044), ('paqoeux', 0.8238755464553833), ('guerre_mondiale', 0.8221109509468079), ('guorre', 0.8160741925239563), ('colonie', 0.8134097456932068), ('majorite', 0.8095427751541138), ('wehrmacht', 0.8062464594841003), ('palestine', 0.8017900586128235), ('classe_ouvriere', 0.7963049411773682), ('wiflielmsirasse', 0.7958565950393677), ('separation', 0.7952693104743958), ('revolution', 0.7949488759040833), ('nombreuses_annees', 0.7941699028015137), ('mandchourie', 0.7938665747642517), ('population_civile', 0.7924997210502625), ('reconnaissance', 0.7918199896812439), ('pahet', 0.7900250554084778)]\n",
      "modèle 4: \n",
      "[('liberation', 0.8756944537162781), ('derniere_guerre', 0.871421754360199), ('guerro', 0.8273341655731201), ('guerre_mondiale', 0.8116095066070557), ('population', 0.8002347350120544), ('capitulation', 0.7899923324584961), ('revolution', 0.7891037464141846), ('palestine', 0.7824346423149109), ('colonie', 0.7823081612586975), ('seconde_guerre_mondiale', 0.7803746461868286), ('repression', 0.7772656679153442), ('premiere_guerre_mondiale', 0.7726887464523315), ('separation', 0.7702820897102356), ('periode_electorale', 0.7642503380775452), ('wehrmacht', 0.7636751532554626), ('russie', 0.7623583078384399), ('guerre_civile', 0.7610481977462769), ('concentration', 0.7565852403640747), ('guorre', 0.7474302053451538), ('crise', 0.7455867528915405)]\n",
      "\n",
      "Exemple 2(travail):\n",
      "modèle 1: \n",
      "[('service', 0.8620229959487915), ('depouillement', 0.8219110369682312), ('fonctionnement', 0.8199041485786438), ('tra_vail', 0.7880679368972778), ('processus', 0.7834004163742065), ('contact', 0.7829896807670593), ('personnel_ouvrier', 0.780623733997345), ('pointage', 0.7773077487945557), ('personnel', 0.7748088240623474), ('bilinguisme', 0.7678170800209045)]\n",
      "modèle 2: \n",
      "[('service', 0.8403620719909668), ('reclassement', 0.7795947194099426), ('fonctionnement', 0.7679724097251892), ('tra_vail', 0.7647817134857178), ('servioe', 0.7627295255661011), ('personnel', 0.7614109516143799), ('controle', 0.7581977844238281), ('servies', 0.7550199031829834), ('bureau_international', 0.7473162412643433), ('personnel_ouvrier', 0.7462013363838196)]\n",
      "modèle 3: \n",
      "[('service', 0.8431075811386108), ('fonctionnement', 0.8125132322311401), ('personnel', 0.7936112284660339), ('tra_vail', 0.7776075601577759), ('service_militaire', 0.7771047949790955), ('personnel_ouvrier', 0.7701247930526733), ('oours', 0.7678736448287964), ('cours_normal', 0.7632794976234436), ('controle', 0.761650800704956), ('chomage', 0.7570000886917114)]\n",
      "modèle 4: \n",
      "[('service', 0.816482663154602), ('service_militaire', 0.8107993006706238), ('fonctionnement', 0.809601902961731), ('service_medical', 0.7788377404212952), ('cours_normal', 0.7753283977508545), ('lkuiue', 0.7733887434005737), ('stage', 0.7625125050544739), ('servioe', 0.7612575888633728), ('personnel', 0.756746768951416), ('problelne', 0.7556949257850647)]\n",
      "\n",
      "Exemple 3(mort):\n",
      "modèle 1: \n",
      "[('memoire', 0.8408652544021606), ('victime', 0.8096931576728821), ('clemence', 0.7893626093864441), ('mort_tragique', 0.7878553867340088), ('detention_perpetuelle', 0.7777940630912781), ('pendaison', 0.7777484655380249), ('naissance', 0.7523590326309204), ('captivite', 0.7498349547386169), ('depouille_mortelle', 0.7484505772590637), ('peine_capitale', 0.7476588487625122)]\n",
      "modèle 2: \n",
      "[('victime', 0.8101502060890198), ('captivite', 0.8039940595626831), ('memoire', 0.7992242574691772), ('pendaison', 0.7489128112792969), ('clemence', 0.7402850985527039), ('depouille_mortelle', 0.738939106464386), ('mort_tragique', 0.7385668754577637), ('rumeur_publique', 0.7327747344970703), ('detention_perpetuelle', 0.7192425727844238), ('naissance', 0.7166368961334229)]\n",
      "modèle 3: \n",
      "[('clemence', 0.8204361796379089), ('captivite', 0.809590756893158), ('plorence', 0.8043772578239441), ('son_fils', 0.7978212833404541), ('victime', 0.7972387075424194), ('memoire', 0.7951624989509583), ('condamnation', 0.7909680008888245), ('pendaison', 0.7877325415611267), ('trahison', 0.7808182835578918), ('bacciochi', 0.7772897481918335)]\n",
      "modèle 4: \n",
      "[('victime', 0.8086892366409302), ('captivite', 0.8024280071258545), ('denonciatrice', 0.7876565456390381), ('clemence', 0.7710268497467041), ('mort_accidentelle', 0.7701247334480286), ('froullay', 0.7624871730804443), ('detention_perpetuelle', 0.7605557441711426), ('fin_tragique', 0.7600277066230774), ('assassine', 0.7599002718925476), ('accusee', 0.7572324275970459)]\n"
     ]
    }
   ],
   "source": [
    "# Explorer le modèle avec most_similar\n",
    "print(\"Exemple 1(guerre):\")\n",
    "for i in range(len(models)):\n",
    "    print(\"modèle \" + str(i+1)+ \": \")\n",
    "    print(models[i].wv.most_similar(\"guerre\", topn=20))\n",
    "print()\n",
    "print(\"Exemple 2(travail):\")   \n",
    "for i in range(len(models)):\n",
    "    print(\"modèle \" + str(i+1)+ \": \")\n",
    "    print(models[i].wv.most_similar(\"travail\", topn=10))\n",
    "print()\n",
    "print(\"Exemple 3(mort):\")    \n",
    "for i in range(len(models)):\n",
    "    print(\"modèle \" + str(i+1)+ \": \")\n",
    "    print(models[i].wv.most_similar(\"mort\", topn=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tac_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
